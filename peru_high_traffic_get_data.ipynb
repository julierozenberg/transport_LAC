{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv,DataFrame,read_excel, merge,concat, Series\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.stats import gaussian_kde\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datacsv          = \"peru_ap17/\"\n",
    "data_peru        = \"peru_data/\"\n",
    "list_csv         = os.listdir(datacsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseline = read_csv(datacsv+\"OD_baseline_Peru.csv\")\n",
    "baseline.index = baseline.Name\n",
    "baseline[\"O\"] = baseline.Name.apply(lambda s: re.search(\"(.*) - (.*)\",s).group(1))\n",
    "baseline[\"D\"] = baseline.Name.apply(lambda s: re.search(\"(.*) - (.*)\",s).group(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial analysis: \"naive\" calculation of costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if os.path.exists(\"costs_peru_ap22.csv\"):\n",
    "    costs_all = read_csv(\"costs_peru_ap22.csv\")\n",
    "else:\n",
    "    costs_all = DataFrame(columns=[\"scenarioID\",\"diff ruc from baseline (%)\",\"diff ruc from baseline (usd)\",\\\n",
    "                               \"missingroutes\",\\\n",
    "                               \"number of affected routes\",\"av cost with traffic (usd)\",\\\n",
    "                               \"max cost with traffic (%)\",\"max cost with traffic (usd)\",\\\n",
    "                               \"av km difference\",\"max km difference\",\"tot km difference\"])\n",
    "    for file in list_csv:\n",
    "        if \".csv\" not in file:\n",
    "            continue\n",
    "        if file==\"OD_baseline_Peru.csv\":\n",
    "            continue\n",
    "        if \"Partial\" in file:\n",
    "            continue\n",
    "        scenar = read_csv(datacsv+file)\n",
    "        scenar.index = scenar.Name\n",
    "        n      = int(re.search('OD_scenario(.*).csv', file).group(1))\n",
    "        ruc    = scenar.Total_Ta_r.sum()\n",
    "        voc    = scenar.Total_Ta_v.sum()\n",
    "        missingroutes = len(baseline)-len(scenar)\n",
    "        baseline_nomissingroutes = baseline.ix[[i in scenar.index for i in baseline.index],:]\n",
    "        diff_from_baseline = 100*(ruc/baseline_nomissingroutes.Total_Ta_r.sum()-1)\n",
    "        diff_from_baseline_abs = ruc-baseline_nomissingroutes.Total_Ta_r.sum()\n",
    "        diff_km_from_baseline  = scenar.Total_KM.sum()-baseline_nomissingroutes.Total_KM.sum()\n",
    "        diff_km = scenar.Total_KM - baseline_nomissingroutes.Total_KM\n",
    "        affected_routes = np.round(scenar.Total_Ta_r/baseline_nomissingroutes.Total_Ta_r,3)!=1\n",
    "        af_cost = 100*(scenar.ix[affected_routes,\"Total_Ta_r\"]*baseline_nomissingroutes.ix[affected_routes,\"avg_TPDA\"]\\\n",
    "        /(baseline_nomissingroutes.ix[affected_routes,\"Total_Ta_r\"]*baseline_nomissingroutes.ix[affected_routes,\"avg_TPDA\"])-1)\n",
    "        af_cost_abs = scenar.ix[affected_routes,\"Total_Ta_r\"]*baseline_nomissingroutes.ix[affected_routes,\"avg_TPDA\"]\\\n",
    "        -(baseline_nomissingroutes.ix[affected_routes,\"Total_Ta_r\"]*baseline_nomissingroutes.ix[affected_routes,\"avg_TPDA\"])\n",
    "\n",
    "        costs_all.loc[len(costs_all),:] = [n,diff_from_baseline,diff_from_baseline_abs,\\\n",
    "                                   missingroutes,sum(affected_routes),\\\n",
    "                                   np.mean(af_cost_abs),np.max(af_cost),np.max(af_cost_abs),\\\n",
    "                                  np.mean(diff_km),np.max(diff_km),diff_km_from_baseline]\n",
    "\n",
    "    costs_all.to_csv(\"costs_peru_ap22.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second analysis: calculation of costs with weights for nodes based on the gravity model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculates weights for each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nodes1 = read_excel(data_peru+\"NODE_CID.xlsx\",\"NODES_CID\")\n",
    "nodes2 = read_excel(data_peru+\"NODES_10km_TPDA.xlsx\",\"NODES_10km_TPDA\")\n",
    "\n",
    "nodes = merge(nodes1, nodes2, on='CID', how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the function below calculates the weight of a OD pair based on the gravity model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseline[\"Ot\"] = baseline.O.replace(nodes.set_index('CID').Sum_TPDA)\n",
    "baseline[\"Dt\"] = baseline.D.replace(nodes.set_index('CID').Sum_TPDA)\n",
    "baseline[\"Opop\"] = baseline.O.replace(nodes.set_index('CID')[\"Population Headcount\"])\n",
    "baseline[\"Dpop\"] = baseline.D.replace(nodes.set_index('CID')[\"Population Headcount\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### here we calculate losses for each scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baseline.ix[baseline.Total_KM!=0,'weights']=baseline.ix[baseline.Total_KM!=0,'Ot']\\\n",
    "                                            *baseline.ix[baseline.Total_KM!=0,'Dt']\\\n",
    "                                            /baseline.ix[baseline.Total_KM!=0,'Total_KM']**2\n",
    "baseline.weights.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "info_links = read_excel(data_peru+\"Traffic_Link_Final.xlsx\",\"Traffic_Link_Final\")\n",
    "#info_links = read_excel(datacsv+\"allinfo.xlsx\",\"Traffic_Link_AllInfo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if os.path.exists(\"costs_peru_may12.csv\"):\n",
    "    costs_all = read_csv(\"costs_peru_may12.csv\")\n",
    "else:\n",
    "    costs_all = DataFrame(columns=[\"scenarioID\",\"partial_or_full\",\"part_ruc_increase\",\"ruc_increase\",\"missingroutes\",\\\n",
    "                               \"num_aff_routes\",\"cost_with_traffic\",\"km_diff\"])\n",
    "    for file in list_csv:\n",
    "        if \".csv\" not in file:\n",
    "            continue\n",
    "        if file==\"OD_baseline_Peru.csv\":\n",
    "            continue\n",
    "        if (\"cluster\" in file):\n",
    "            continue\n",
    "        if (\"Partial_V2\" in file):\n",
    "            partial_or_full=\"partial\"\n",
    "            n      = int(re.search('Scenario_OD(.*)_Partial_V2.csv', file).group(1))\n",
    "            part_ruc_increase = 0.05\n",
    "        elif (\"Partial_v1\" in file):\n",
    "            partial_or_full=\"partial\"\n",
    "            n      = int(re.search('Scenario_OD(.*)_Partial_v1.csv', file).group(1))\n",
    "            part_ruc_increase = 0.5\n",
    "        else:\n",
    "            partial_or_full='full'\n",
    "            n      = int(re.search('OD_scenario(.*).csv', file).group(1))\n",
    "            part_ruc_increase = 0.\n",
    "        scenar = read_csv(datacsv+file)\n",
    "        scenar.index = scenar.Name\n",
    "        \n",
    "        missingroutes = len(baseline)-len(scenar)\n",
    "        # we do not take into account the routes that don't have a second best solution\n",
    "        baseline_nm = baseline.ix[[i in scenar.index for i in baseline.index],:]\n",
    "        # we select only routes that get affected by the disruption\n",
    "        affected_routes = (np.round(scenar.Total_Ta_r/baseline_nm.Total_Ta_r,3)!=1)&(baseline_nm.Total_Ta_r>0)\n",
    "        subscenar = scenar.ix[affected_routes,:]\n",
    "        subscenar[\"weights\"] = baseline_nm.weights\n",
    "        \n",
    "        traffic = info_links.ix[info_links.ScenarioID,\"TPDA\"].values[0]\n",
    "            \n",
    "        diff_ruc_baseline   = (subscenar.Total_Ta_r-\\\n",
    "                               baseline_nm.ix[affected_routes,\"Total_Ta_r\"])\n",
    "        diff_km_from_baseline = (subscenar.Total_KM-baseline_nm.ix[affected_routes,\"Total_KM\"])\n",
    "        diff_tot_baseline   = (traffic*diff_ruc_baseline)\n",
    "        \n",
    "        ruc_increase      = np.sum(diff_ruc_baseline*subscenar.weights)/subscenar.weights.sum()\n",
    "        km_diff = np.sum(diff_km_from_baseline*subscenar.weights)/subscenar.weights.sum()\n",
    "        cost_with_traffic  = np.sum(diff_tot_baseline*subscenar.weights)/subscenar.weights.sum()\n",
    "\n",
    "        costs_all.loc[len(costs_all),:] = [n,partial_or_full,part_ruc_increase,\\\n",
    "                                           ruc_increase,missingroutes,sum(affected_routes),\\\n",
    "                                           cost_with_traffic,km_diff]\n",
    "\n",
    "    costs_all.to_csv(\"costs_peru_may12.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here I merge the info that CJ sent with the results of the analysis (calculation of disruption costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allinfo = merge(info_links, costs_all.rename(columns={\"scenarioID\":\"ScenarioID\"}), on='ScenarioID', how='inner')\n",
    "allinfo.index=allinfo.ScenarioID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clusters of links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster1 = np.array([i in [195, 567, 568, 569, 570, 572, 719, 720] for i in allinfo.ScenarioID])\n",
    "cluster2 = np.array([i in [135,136,138,139,140,545,654] for i in allinfo.ScenarioID])\n",
    "cluster3 = np.array([i in [124, 126, 131, 622, 623, 624, 642, 643, 645]+list(range(594,621))\\\n",
    "                     for i in allinfo.ScenarioID])\n",
    "cluster4 = np.array([i in [271,272] for i in allinfo.ScenarioID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "costs_clusters = DataFrame(columns=[\"ScenarioID\",\"partial_or_full\",'part_ruc_increase',\"ruc_increase\",\"missingroutes\",\\\n",
    "                           \"num_aff_routes\",\"cost_with_traffic\",\"km_diff\"])\n",
    "for file in list_csv:\n",
    "    if \".csv\" not in file:\n",
    "        continue\n",
    "    if \"cluster\" not in file:\n",
    "        continue\n",
    "    if (\"partial\" in file):\n",
    "        partial_or_full=\"partial\"\n",
    "        n      = int(re.search('OD_scenario_cluster(.*)_partial.csv', file).group(1))\n",
    "        part_ruc_increase = 0.05\n",
    "    else:\n",
    "        partial_or_full=\"full\"\n",
    "        n      = int(re.search('OD_scenario_cluster(.*).csv', file).group(1))\n",
    "        part_ruc_increase = 0.\n",
    "    scenar = read_csv(datacsv+file)\n",
    "    scenar.index = scenar.Name\n",
    "    \n",
    "\n",
    "    missingroutes = len(baseline)-len(scenar)\n",
    "    # we do not take into account the routes that don't have a second best solution\n",
    "    baseline_nm = baseline.ix[[i in scenar.index for i in baseline.index],:]\n",
    "    # we select only routes that get affected by the disruption\n",
    "    affected_routes = (np.round(scenar.Total_Ta_r/baseline_nm.Total_Ta_r,3)!=1)&(baseline_nm.Total_Ta_r!=0)\n",
    "    subscenar = scenar.ix[affected_routes,:]\n",
    "    subscenar[\"weights\"] = baseline_nm.ix[affected_routes,'weights']\n",
    "\n",
    "    traffic = info_links.ix[info_links.ScenarioID,\"TPDA\"].values[0]\n",
    "\n",
    "    diff_ruc_baseline   = (subscenar.Total_Ta_r-\\\n",
    "                           baseline_nm.ix[affected_routes,\"Total_Ta_r\"]).dropna()\n",
    "    diff_km_from_baseline = (subscenar.Total_KM-\\\n",
    "                             baseline_nm.ix[affected_routes,\"Total_KM\"]).dropna()\n",
    "    diff_tot_baseline   = (traffic*diff_ruc_baseline).dropna()\n",
    "    \n",
    "    if sum(affected_routes)>0:\n",
    "        ruc_increase      = np.sum(diff_ruc_baseline*subscenar.weights)/subscenar.weights.sum()\n",
    "        km_diff = np.sum(diff_km_from_baseline*subscenar.weights)/subscenar.weights.sum()\n",
    "        cost_with_traffic  = np.sum(diff_tot_baseline*subscenar.weights)/subscenar.weights.sum()\n",
    "    else:\n",
    "        ruc_increase      = 0\n",
    "        km_diff = 0\n",
    "        cost_with_traffic  = 0\n",
    "\n",
    "    costs_clusters.loc[len(costs_clusters),:] = [\"cluster{}\".format(n),partial_or_full,part_ruc_increase,\\\n",
    "                                                 ruc_increase,missingroutes,sum(affected_routes),\\\n",
    "                                       cost_with_traffic,km_diff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allinfo = allinfo.append(costs_clusters,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for clu in ['cluster2', 'cluster3', 'cluster4']:\n",
    "\n",
    "    for col in ['ADMIN_NAME', 'CITY_NAME', 'CLASS', 'CNTRY_NAME', 'CODIGO', 'COND1', 'CORR_ID','Identifier',\\\n",
    "               'LANES', 'NAME_0', 'OD', 'OPTIMAL', 'STATUS', 'STATUS.1', 'SURFACE1','TERRAIN', 'TID',]:\n",
    "        allinfo.ix[allinfo.ScenarioID==clu,col]=allinfo.ix[eval(clu),col].iloc[0]\n",
    "\n",
    "    for climat in ['EU_historical','GFDL_8.5','HadGEM2_8.5','IPSL_8.5']:\n",
    "        for RP in [5,10,25,50,100,250,500,1000]:\n",
    "            col = \"{}_RP{} (cm)\".format(climat,RP)\n",
    "            allinfo.ix[allinfo.ScenarioID==clu,col]=allinfo.ix[eval(clu),col].max()\n",
    "\n",
    "    for col in [\"KM\"]:\n",
    "        allinfo.ix[allinfo.ScenarioID==clu,col]=allinfo.ix[eval(clu),col].sum()\n",
    "\n",
    "    for col in ['Elev_Max (m)','TPDA']:\n",
    "        allinfo.ix[allinfo.ScenarioID==clu,col]=allinfo.ix[eval(clu),col].max()\n",
    "\n",
    "    for col in ['Elev_Min (m)']:\n",
    "        allinfo.ix[allinfo.ScenarioID==clu,col]=allinfo.ix[eval(clu),col].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster1 = np.array([i in [195, 567, 568, 569, 570, 572, 719, 720] for i in allinfo.ScenarioID])\n",
    "cluster2 = np.array([i in [135,136,138,139,140,545,654] for i in allinfo.ScenarioID])\n",
    "cluster3 = np.array([i in [124, 126, 131, 622, 623, 624, 642, 643, 645]+list(range(594,621))\\\n",
    "                     for i in allinfo.ScenarioID])\n",
    "cluster4 = np.array([i in [271,272] for i in allinfo.ScenarioID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allinfo.to_csv(\"allinfo_peru.csv\",index=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.3.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
